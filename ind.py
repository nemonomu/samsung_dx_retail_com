"""
Amazon India ê°€ê²© ì¶”ì¶œ ì‹œìŠ¤í…œ - ì¸ë„ ì „ìš© ë²„ì „
ì£¼ìš” íŠ¹ì§•:
1. ì¸ë„ ì „ìš© ì„ íƒì ë° ì„¤ì •
2. ê°œì„ ëœ ships_from ì„ íƒì
3. ë£¨í”¼(â‚¹) ê°€ê²© ì²˜ë¦¬
4. ì¸ë„ íŠ¹í™” VAT/GST ì²˜ë¦¬
5. ships_fromê³¼ sold_by ëª¨ë‘ ì—†ì„ ê²½ìš° ê°€ê²© 0 ì²˜ë¦¬
"""
import undetected_chromedriver as uc
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException
import pandas as pd
import pymysql
from sqlalchemy import create_engine
import paramiko
import time
import random
import re
from datetime import datetime
import pytz
import logging
import os
from io import StringIO
import json

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Import database configuration
from config import DB_CONFIG

# íŒŒì¼ì„œë²„ ì„¤ì •
FILE_SERVER_CONFIG = {
    'host': '3.36.101.24',
    'port': 22,
    'username': 'ftpuser',
    'password': 'samsung0701!',
    'upload_path': '/home/ftpuser/uploads'
}

class AmazonIndiaScraper:
    def __init__(self):
        self.driver = None
        self.db_engine = None
        self.country_code = 'in'
        self.wait = None
        self.korea_tz = pytz.timezone('Asia/Seoul')
        
        # DB ì—°ê²° ì„¤ì •
        self.setup_db_connection()
        
        # ì¸ë„ ì „ìš© ì„ íƒì ì„¤ì •
        self.setup_india_selectors()
        
        # DBì—ì„œ ì„ íƒì ë¡œë“œ (ë®ì–´ì“°ê¸°/ë³‘í•©)
        self.load_selectors_from_db()
        
    def setup_db_connection(self):
        """DB ì—°ê²° ì„¤ì •"""
        try:
            connection_string = (
                f"mysql+pymysql://{DB_CONFIG['user']}:{DB_CONFIG['password']}@"
                f"{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}"
            )
            self.db_engine = create_engine(connection_string)
            logger.info("DB ì—°ê²° ì„¤ì • ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"DB ì—°ê²° ì‹¤íŒ¨: {e}")
            self.db_engine = None
    
    def setup_india_selectors(self):
        """ì¸ë„ ì „ìš© ì„ íƒì ì„¤ì • - ì •í™•í•œ ê°€ê²© ì„ íƒìë§Œ ì‚¬ìš©"""
        self.selectors = {
            'in': {
                'price': [
                    # ë©”ì¸ ê°€ê²© í‘œì‹œ ì˜ì—­ (ê°€ì¥ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì„ íƒìë“¤)
                    "span.a-price-whole",
                    "//span[@class='a-price-whole']",
                    "//div[@id='corePriceDisplay_desktop_feature_div']//span[@class='a-price-whole']",
                    "//div[@class='a-section a-spacing-none aok-align-center']//span[@class='a-price-whole']",
                    "#apex_desktop .a-price-whole",
                    "//span[@class='a-price a-text-price a-size-medium a-color-price']//span[@class='a-price-whole']",
                    "//div[@id='price_inside_buybox']//span[@class='a-price-whole']",
                    
                    # ë°±ì—… ì„ íƒìë“¤ (ë©”ì¸ì´ ì‹¤íŒ¨í•  ë•Œë§Œ)
                    ".a-price.a-text-price.a-size-medium .a-offscreen",
                    "//span[@class='a-price']//span[@class='a-offscreen']",
                    "span.a-price-range span.a-price-whole",
                    "div.a-section.a-spacing-micro span.a-price-whole",
                    "[data-a-color='price'] .a-offscreen",
                    ".a-price-range .a-price .a-offscreen"
                ],
                'title': [
                    "#productTitle",
                    "//span[@id='productTitle']",
                    "//h1/span[@id='productTitle']",
                    "h1#title span",
                    "//div[@id='titleSection']//h1//span"
                ],
                'ships_from': [
                    # ìƒˆë¡œ ì¶”ê°€ëœ ì„ íƒìë“¤ì„ ìµœìš°ì„ ìœ¼ë¡œ ë°°ì¹˜
                    "//*[@id='fulfillerInfoFeature_feature_div']/div[2]/div[1]/span",
                    "/html/body/div[2]/div/div/div[5]/div[1]/div[4]/div/div[1]/div/div/div/form/div/div/div/div/div[4]/div/div[19]/div/div/div[1]/div/div[2]/div[2]/div[1]/span",
                    # ê¸°ì¡´ ì„ íƒìë“¤
                    "//span[contains(text(), 'Ships from')]/following-sibling::span",
                    "//div[@id='merchant-info']//a",
                    "//div[@tabular-attribute-name='Ships from']//span",
                    "//span[@class='tabular-buybox-text'][1]",
                    "//div[@id='fulfillerInfoFeature_feature_div']//span",
                    "//div[contains(@class, 'tabular-buybox-container')]//span[contains(text(), 'Ships from')]/../following-sibling::span",
                    "//div[@class='tabular-buybox-container']//span[@class='tabular-buybox-text']",
                    "//div[@id='merchant-info']//span",
                    "//span[contains(text(), 'Dispatched from')]/../following-sibling::span",
                    "//div[@data-feature-name='fulfillerInfo']//span",
                    "//div[contains(@class, 'a-row')]//span[contains(text(), 'Ships from')]/../span[2]",
                    "//table[@id='productDetails_techSpec_section_1']//span[contains(text(), 'Ships from')]/../following-sibling::td/span"
                ],
                'sold_by': [
                    # ìƒˆë¡œ ì¶”ê°€ëœ ì„ íƒìë“¤ì„ ìµœìš°ì„ ìœ¼ë¡œ ë°°ì¹˜
                    "//*[@id='sellerProfileTriggerId']",
                    "/html/body/div[2]/div/div/div[5]/div[1]/div[4]/div/div[1]/div/div/div/form/div/div/div/div/div[4]/div/div[19]/div/div/div[1]/div/div[3]/div[2]/div[1]/span/a",
                    # ê¸°ì¡´ ì„ íƒìë“¤
                    "//span[contains(text(), 'Sold by')]/following-sibling::span",
                    "//div[@id='merchant-info']//a",
                    "//a[@id='sellerProfileTriggerId']",
                    "//div[@tabular-attribute-name='Sold by']//span",
                    "//span[@class='tabular-buybox-text'][2]",
                    "//div[@id='fulfillerInfoFeature_feature_div']//a",
                    "//div[contains(@class, 'tabular-buybox-container')]//span[contains(text(), 'Sold by')]/../following-sibling::span",
                    "//span[contains(text(), 'Sold by')]/../following-sibling::span//a",
                    "//div[@data-feature-name='fulfillerInfo']//a"
                ],
                'imageurl': [
                    "//div[@id='imageBlock']//img[@id='landingImage']",
                    "//div[@id='main-image-container']//img",
                    "//img[@class='a-dynamic-image']",
                    "//div[@class='imgTagWrapper']//img",
                    "//div[@id='imageBlock_feature_div']//img",
                    "//img[@data-old-hires]"
                ],
                'availability': [
                    "//div[@id='availability']//span",
                    "//div[@id='availability_feature_div']//span",
                    "//span[@class='a-size-medium a-color-success']",
                    "//span[@class='a-size-medium a-color-price']",
                    "//div[@id='availability']//span[@class='a-size-medium']",
                    "//span[contains(text(), 'In stock')]",
                    "//span[contains(text(), 'Available')]"
                ],
                # 'vat_text_list': [
                #     # ì¸ë„ GST ë° ì„¸ê¸ˆ ê´€ë ¨ í…ìŠ¤íŠ¸
                #     "GST included",
                #     "Inclusive of all taxes",
                #     "Including all taxes",
                #     "Includes all taxes",
                #     "Tax included",
                #     "Tax inclusive",
                #     "Including tax",
                #     "Inc. tax",
                #     "Including GST",
                #     "GST inclusive",
                #     "All taxes included",
                #     "Price inclusive of taxes",
                #     "MRP inclusive of all taxes",
                #     "Price includes taxes"
                # ],
                'stock_flag': [
                    'Currently unavailable',
                    'Out of Stock',
                    'Temporarily out of stock',
                    'Currently not available',
                    'This item is currently unavailable'
                ],
                'blocked_patterns': [
                    'sorry',
                    'robot check',
                    '503 Service Unavailable',
                    'Something went wrong',
                    'access denied',
                    'enter the characters',
                    'verify you are human'
                ]
            }
        }
    
    def load_selectors_from_db(self):
        """DBì—ì„œ Amazon Indiaìš© ì„ íƒì ë¡œë“œ"""
        if not self.db_engine:
            logger.warning("DB ì—°ê²°ì´ ì—†ì–´ ì„ íƒì ë¡œë“œ ë¶ˆê°€")
            return
            
        try:
            query = """
            SELECT element_type, selector_value, priority
            FROM amazon_selectors
            WHERE country_code = 'in' 
              AND is_active = TRUE
              AND selector_value NOT LIKE '/html/%'
            ORDER BY element_type, priority ASC
            """
            
            df = pd.read_sql(query, self.db_engine)
            logger.info(f"DBì—ì„œ ì¸ë„ ì„ íƒì ë¡œë“œ: {len(df)}ê°œ")
            
            # DBì—ì„œ ë¡œë“œí•œ ì„ íƒìë¡œ ë®ì–´ì“°ê¸°
            db_selectors = {'in': {}}
            
            for element_type in df['element_type'].unique():
                db_selectors['in'][element_type] = df[df['element_type'] == element_type]['selector_value'].tolist()
                logger.info(f"  - {element_type}: {len(db_selectors['in'][element_type])}ê°œ")
            
            # ê¸°ë³¸ê°’ê³¼ ë³‘í•© (DB ìš°ì„ )
            for element_type, selectors in db_selectors['in'].items():
                if element_type in self.selectors['in']:
                    existing = self.selectors['in'][element_type]
                    self.selectors['in'][element_type] = selectors + [s for s in existing if s not in selectors]
                else:
                    self.selectors['in'][element_type] = selectors
            
            logger.info("ì¸ë„ DB ì„ íƒì ë¡œë“œ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"DB ì„ íƒì ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def setup_driver(self):
        """Chrome ë“œë¼ì´ë²„ ì„¤ì • - ì¸ë„ ì „ìš©"""
        logger.info("Chrome ë“œë¼ì´ë²„ ì„¤ì • ì¤‘ (ì¸ë„ ì „ìš©)...")
        
        try:
            options = uc.ChromeOptions()
            
            # ê¸°ë³¸ ì˜µì…˜ë“¤
            options.add_argument('--disable-blink-features=AutomationControlled')
            options.add_argument('--disable-dev-shm-usage')
            options.add_argument('--no-sandbox')
            options.add_argument('--disable-setuid-sandbox')
            options.add_argument('--disable-web-security')
            options.add_argument('--disable-features=VizDisplayCompositor')
            
            # ì¸ë„ ì „ìš© User-Agent
            india_user_agents = [
                'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
            ]
            options.add_argument(f'--user-agent={random.choice(india_user_agents)}')
            
            # ì¸ë„ ì–¸ì–´ ì„¤ì •
            options.add_experimental_option('prefs', {
                'intl.accept_languages': 'en-IN,en,hi',
                'profile.default_content_settings.popups': 0,
                'profile.default_content_setting_values.notifications': 2
            })
            
            # Chrome ë“œë¼ì´ë²„ ìƒì„±
            self.driver = uc.Chrome(options=options)
            self.driver.maximize_window()
            
            # WebDriverWait ê°ì²´ ìƒì„±
            self.wait = WebDriverWait(self.driver, 20)
            
            logger.info("ì¸ë„ ì „ìš© ë“œë¼ì´ë²„ ì„¤ì • ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"ë“œë¼ì´ë²„ ì„¤ì • ì‹¤íŒ¨: {e}")
            return False
    
    def click_blue_link_and_return(self, original_url):
        """íŒŒë€ìƒ‰ ë§í¬ í´ë¦­ í›„ ì›ë˜ URLë¡œ ëŒì•„ê°€ê¸°"""
        try:
            logger.info("íŒŒë€ìƒ‰ ë§í¬ ì°¾ëŠ” ì¤‘...")
            
            # íŒŒë€ìƒ‰ ë§í¬ ì„ íƒìë“¤ (ì¸ë„ íŠ¹í™”)
            blue_link_selectors = [
                # íŒë””ì–´
                "//a[contains(text(), 'à¤µà¤¾à¤ªà¤¸ à¤œà¤¾à¤à¤‚')]",
                "//a[contains(text(), 'à¤¹à¥‹à¤®à¤ªà¥‡à¤œ à¤ªà¤° à¤µà¤¾à¤ªà¤¸')]",
                # ì˜ì–´
                "//a[contains(text(), 'Click here to go back')]",
                "//a[contains(text(), 'back to Amazon')]",
                "//a[contains(text(), 'Go back to Amazon')]",
                "//a[contains(text(), 'Return to Amazon')]",
                # ì¼ë°˜ì ì¸ íŒ¨í„´
                "//a[contains(@href, 'amazon.in')]",
                "//a[contains(@href, 'amazon.')]",
                "//a[contains(@class, 'a-link')]"
            ]
            
            # íŒŒë€ìƒ‰ ë§í¬ í´ë¦­ ì‹œë„
            for selector in blue_link_selectors:
                try:
                    link = self.driver.find_element(By.XPATH, selector)
                    if link.is_displayed():
                        link_text = link.text.strip()
                        logger.info(f"íŒŒë€ìƒ‰ ë§í¬ ë°œê²¬: '{link_text}'")
                        
                        # ë§í¬ í´ë¦­
                        link.click()
                        logger.info("íŒŒë€ìƒ‰ ë§í¬ í´ë¦­ ì™„ë£Œ")
                        
                        # ì ì‹œ ëŒ€ê¸°
                        time.sleep(random.uniform(2, 4))
                        
                        # ì›ë˜ URLë¡œ ë‹¤ì‹œ ì ‘ì†
                        logger.info(f"ì›ë˜ URLë¡œ ì¬ì ‘ì†: {original_url}")
                        self.driver.get(original_url)
                        
                        # í˜ì´ì§€ ë¡œë“œ ëŒ€ê¸°
                        time.sleep(random.uniform(3, 5))
                        
                        return True
                        
                except Exception as e:
                    logger.debug(f"ì„ íƒì ì‹œë„ ì‹¤íŒ¨: {selector} - {e}")
                    continue
            
            logger.warning("íŒŒë€ìƒ‰ ë§í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            return False
            
        except Exception as e:
            logger.error(f"íŒŒë€ìƒ‰ ë§í¬ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return False

    def handle_captcha_or_block_page(self, original_url=None):
        """ì°¨ë‹¨ í˜ì´ì§€ë‚˜ ìº¡ì°¨ ì²˜ë¦¬"""
        try:
            logger.info("ì°¨ë‹¨/ìº¡ì°¨ í˜ì´ì§€ í™•ì¸ ì¤‘...")
            
            # íŒŒë€ìƒ‰ ë§í¬ ìš°íšŒ ì‹œë„ (ìš°ì„ ìˆœìœ„)
            if original_url and self.click_blue_link_and_return(original_url):
                logger.info("íŒŒë€ìƒ‰ ë§í¬ ìš°íšŒ ì„±ê³µ")
                return True
            
            # Continue shopping ë²„íŠ¼ ì°¾ê¸°
            continue_selectors = [
                "//button[contains(text(), 'Continue shopping')]",
                "//button[contains(@class, 'a-button-primary')]",
                "//input[@type='submit' and contains(@value, 'Continue')]",
                "//a[contains(text(), 'Continue shopping')]",
                "//span[contains(text(), 'Continue shopping')]/ancestor::button",
                "button.a-button-primary",
                "button[type='submit']",
                "#a-autoid-0",
                ".a-button-inner"
            ]
            
            for selector in continue_selectors:
                try:
                    if selector.startswith('//'):
                        button = self.driver.find_element(By.XPATH, selector)
                    else:
                        button = self.driver.find_element(By.CSS_SELECTOR, selector)
                    
                    if button and button.is_displayed():
                        logger.info(f"âœ… Continue ë²„íŠ¼ ë°œê²¬: {selector}")
                        button.click()
                        time.sleep(3)
                        logger.info("âœ… Continue ë²„íŠ¼ í´ë¦­ ì™„ë£Œ")
                        return True
                        
                except Exception:
                    continue
            
            return False
            
        except Exception as e:
            logger.error(f"ì°¨ë‹¨ í˜ì´ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            return False
    
    def is_page_blocked(self):
        """í˜ì´ì§€ ì°¨ë‹¨ ê°ì§€ - ê°œì„ ëœ ë¡œì§"""
        try:
            page_title = self.driver.title.lower()
            page_source = self.driver.page_source.lower()
            current_url = self.driver.current_url.lower()
            
            # 1. ì •ìƒ í˜ì´ì§€ í™•ì¸ (ìš°ì„  ì²´í¬)
            normal_indicators = [
                'add to cart',
                'buy now',
                'product title',
                'price',
                'availability',
                'customer reviews',
                'product details',
                'ships from',
                'sold by'
            ]
            
            normal_count = sum(1 for indicator in normal_indicators if indicator in page_source)
            
            # ì •ìƒ ì§€í‘œê°€ 3ê°œ ì´ìƒì´ë©´ ì •ìƒ í˜ì´ì§€
            if normal_count >= 3:
                logger.info(f"âœ… ì •ìƒ í˜ì´ì§€ í™•ì¸: {normal_count}ê°œ ì§€í‘œ ë°œê²¬")
                return False
            
            # 2. ëª…í™•í•œ ì°¨ë‹¨ ì§•í›„ë§Œ ì²´í¬
            serious_blocked_indicators = [
                'enter the characters you see below',
                'to continue shopping, please type the characters',
                'verify you are human',
                'access denied',
                'automated access',
                'suspicious activity',
                '503 service unavailable',
                'sorry, we just need to make sure you',
                'are you a robot'
            ]
            
            for pattern in serious_blocked_indicators:
                if pattern in page_source:
                    logger.warning(f"ğŸš« ëª…í™•í•œ ì°¨ë‹¨ ê°ì§€: '{pattern}'")
                    return True
            
            # 3. Amazon India ë„ë©”ì¸ í™•ì¸
            if 'amazon.in' not in current_url:
                logger.warning(f"Amazon India í˜ì´ì§€ê°€ ì•„ë‹˜: {current_url}")
                return True
            
            # 4. í˜ì´ì§€ ì œëª© í™•ì¸
            if 'sorry' in page_title or 'error' in page_title:
                logger.warning(f"ğŸš« ì˜¤ë¥˜ í˜ì´ì§€ ì œëª©: {page_title}")
                return True
            
            # 5. ê¸°ë³¸ì ì¸ Amazon ìš”ì†Œ í™•ì¸
            essential_elements = ['productTitle', 'price', 'availability', 'add-to-cart']
            found_elements = 0
            
            for element_id in essential_elements:
                try:
                    self.driver.find_element(By.ID, element_id)
                    found_elements += 1
                except:
                    pass
            
            # í•„ìˆ˜ ìš”ì†Œê°€ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ ì°¨ë‹¨ ê°€ëŠ¥ì„±
            if found_elements == 0:
                logger.warning("âš ï¸ í•„ìˆ˜ ìš”ì†Œ ì—†ìŒ - ì°¨ë‹¨ ê°€ëŠ¥ì„± ìˆìŒ")
                # í•˜ì§€ë§Œ ë°”ë¡œ ì°¨ë‹¨ìœ¼ë¡œ íŒë‹¨í•˜ì§€ ë§ê³  ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ í™•ì¸
                return False
            
            logger.info(f"âœ… ì •ìƒ í˜ì´ì§€ë¡œ íŒë‹¨ (í•„ìˆ˜ ìš”ì†Œ: {found_elements}ê°œ)")
            return False
            
        except Exception as e:
            logger.error(f"í˜ì´ì§€ ì°¨ë‹¨ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
            return False
    
    def extract_price_india(self):
        """ì¸ë„ ë£¨í”¼ ê°€ê²© ì¶”ì¶œ"""
        price_selectors = self.selectors['in']['price']
        
        logger.info(f"\në£¨í”¼ ê°€ê²© ì¶”ì¶œ ì‹œì‘ - ì„ íƒì: {len(price_selectors)}ê°œ")
        
        for idx, selector in enumerate(price_selectors, 1):
            try:
                logger.info(f"\n  [{idx}/{len(price_selectors)}] ê°€ê²© ì„ íƒì ì‹œë„: {selector}")
                
                if selector.startswith('//'):
                    elements = WebDriverWait(self.driver, 3).until(
                        EC.presence_of_all_elements_located((By.XPATH, selector))
                    )
                else:
                    elements = WebDriverWait(self.driver, 3).until(
                        EC.presence_of_all_elements_located((By.CSS_SELECTOR, selector))
                    )
                
                logger.info(f"      ë°œê²¬ëœ ìš”ì†Œ: {len(elements)}ê°œ")
                
                for i, element in enumerate(elements):
                    try:
                        if element.is_displayed():
                            # ì—¬ëŸ¬ ë°©ë²•ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                            text1 = element.text.strip()
                            text2 = element.get_attribute('textContent').strip() if element.get_attribute('textContent') else ""
                            text3 = element.get_attribute('innerText').strip() if element.get_attribute('innerText') else ""
                            
                            price_text = max([text1, text2, text3], key=len)
                            
                            if price_text:
                                logger.info(f"        í…ìŠ¤íŠ¸: '{price_text}'")
                                
                                # ì¸ë„ ë£¨í”¼ íŒŒì‹±
                                price = self.parse_rupee_price(price_text)
                                if price:
                                    logger.info(f"      âœ… ë£¨í”¼ ê°€ê²© ì¶”ì¶œ ì„±ê³µ: {price} (ì›ë³¸: {price_text})")
                                    return price
                    
                    except Exception as e:
                        logger.error(f"      ìš”ì†Œ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                
            except TimeoutException:
                logger.info("      íƒ€ì„ì•„ì›ƒ")
            except Exception as e:
                logger.error(f"      ì˜¤ë¥˜: {str(e)}")
        
        # JavaScriptë¡œ ë£¨í”¼ ê°€ê²© ì°¾ê¸°
        logger.info("\nğŸ’¡ JavaScriptë¡œ ë£¨í”¼ ê°€ê²© ê²€ìƒ‰...")
        try:
            js_result = self.driver.execute_script("""
                const elements = document.querySelectorAll('span, div');
                const results = [];
                
                for (let elem of elements) {
                    const text = elem.textContent.trim();
                    // ë£¨í”¼ ê°€ê²© íŒ¨í„´ ë§¤ì¹­
                    if (text.match(/â‚¹[\d,]+\.?\d*/) || text.match(/\d+[.,]\d{2}/) || text.match(/â‚¹\s*\d/)) {
                        if (text.length < 30) {
                            results.push({
                                text: text,
                                tag: elem.tagName,
                                class: elem.className
                            });
                        }
                    }
                }
                
                return results.slice(0, 10);
            """)
            
            if js_result:
                logger.info(f"  JavaScript ê²°ê³¼: {len(js_result)}ê°œ")
                for r in js_result:
                    logger.info(f"    - '{r['text']}'")
                    price = self.parse_rupee_price(r['text'])
                    if price:
                        logger.info(f"  âœ… JavaScript ë£¨í”¼ ê°€ê²© ì¶”ì¶œ ì„±ê³µ: {price}")
                        return price
                        
        except Exception as e:
            logger.error(f"  JavaScript ê°€ê²© ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        
        logger.error("\në£¨í”¼ ê°€ê²© ì¶”ì¶œ ì™„ì „ ì‹¤íŒ¨")
        return None
    
    def parse_rupee_price(self, price_text):
        """ë£¨í”¼ ê°€ê²© íŒŒì‹± - í†µí™”ê¸°í˜¸ ì™„ì „ ì œê±°, ì •ìˆ˜/ì†Œìˆ˜ì  ìë™ ì²˜ë¦¬"""
        try:
            # ê¸°ë³¸ ì •ë¦¬
            price_text = price_text.strip()
            logger.debug(f"ì›ë³¸ ê°€ê²© í…ìŠ¤íŠ¸: '{price_text}'")
            
            # ë£¨í”¼ ê¸°í˜¸ì™€ ê³µë°± ì œê±°
            price_text = re.sub(r'[â‚¹\s]', '', price_text)
            
            # ì½¤ë§ˆ ì œê±°
            price_text = price_text.replace(',', '')
            
            # ìˆ«ìë§Œ ì¶”ì¶œ
            match = re.search(r'(\d+\.?\d*)', price_text)
            if match:
                price = float(match.group(1))
                
                # ì†Œìˆ˜ì  ì´í•˜ê°€ 0ì´ë©´ ì •ìˆ˜ë¡œ ë³€í™˜
                if price == int(price):
                    price = int(price)
                    logger.debug(f"íŒŒì‹±ëœ ê°€ê²© (ì •ìˆ˜): {price}")
                else:
                    logger.debug(f"íŒŒì‹±ëœ ê°€ê²© (ì†Œìˆ˜): {price}")
                
                return price
                
        except Exception as e:
            logger.debug(f"ë£¨í”¼ ê°€ê²© íŒŒì‹± ì˜¤ë¥˜: {price_text} - {e}")
            
        return None
    
    def extract_ships_from_india(self):
        """ì¸ë„ ì „ìš© ships_from ì¶”ì¶œ"""
        ships_from_selectors = self.selectors['in']['ships_from']
        
        logger.info(f"\nShips From ì¶”ì¶œ ì‹œì‘ - ì„ íƒì: {len(ships_from_selectors)}ê°œ")
        
        for idx, selector in enumerate(ships_from_selectors, 1):
            try:
                logger.info(f"\n  [{idx}/{len(ships_from_selectors)}] Ships From ì„ íƒì ì‹œë„: {selector}")
                
                if selector.startswith('//'):
                    elements = self.driver.find_elements(By.XPATH, selector)
                else:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                
                logger.info(f"      ë°œê²¬ëœ ìš”ì†Œ: {len(elements)}ê°œ")
                
                for i, element in enumerate(elements):
                    try:
                        if element.is_displayed():
                            text = element.text.strip()
                            if text:
                                logger.info(f"      Ships From ì¶”ì¶œ ì„±ê³µ: '{text}'")
                                return text
                    except Exception as e:
                        logger.error(f"      ìš”ì†Œ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                
            except Exception as e:
                logger.error(f"      ì˜¤ë¥˜: {str(e)}")
        
        logger.error("\nShips From ì¶”ì¶œ ì‹¤íŒ¨")
        return None
    
    def extract_sold_by_india(self):
        """ì¸ë„ ì „ìš© sold_by ì¶”ì¶œ"""
        sold_by_selectors = self.selectors['in']['sold_by']
        
        logger.info(f"\nSold By ì¶”ì¶œ ì‹œì‘ - ì„ íƒì: {len(sold_by_selectors)}ê°œ")
        
        for idx, selector in enumerate(sold_by_selectors, 1):
            try:
                logger.info(f"\n  [{idx}/{len(sold_by_selectors)}] Sold By ì„ íƒì ì‹œë„: {selector}")
                
                if selector.startswith('//'):
                    elements = self.driver.find_elements(By.XPATH, selector)
                else:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                
                logger.info(f"      ë°œê²¬ëœ ìš”ì†Œ: {len(elements)}ê°œ")
                
                for i, element in enumerate(elements):
                    try:
                        if element.is_displayed():
                            text = element.text.strip()
                            if text:
                                logger.info(f"      Sold By ì¶”ì¶œ ì„±ê³µ: '{text}'")
                                return text
                    except Exception as e:
                        logger.error(f"      ìš”ì†Œ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                
            except Exception as e:
                logger.error(f"      ì˜¤ë¥˜: {str(e)}")
        
        logger.error("\nSold By ì¶”ì¶œ ì‹¤íŒ¨")
        return None
    
    def extract_element_text(self, selectors, element_name="ìš”ì†Œ"):
        """ì„ íƒì ëª©ë¡ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        logger.info(f"\n{element_name} ì¶”ì¶œ ì‹œì‘ - ì´ {len(selectors)}ê°œ ì„ íƒì")
        
        for idx, selector in enumerate(selectors, 1):
            try:
                logger.info(f"\n  [{idx}/{len(selectors)}] ì‹œë„: {selector}")
                
                if selector.startswith('//') or selector.startswith('('):
                    elements = self.driver.find_elements(By.XPATH, selector)
                else:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                
                logger.info(f"      ë°œê²¬ëœ ìš”ì†Œ: {len(elements)}ê°œ")
                
                if elements:
                    for i, element in enumerate(elements):
                        try:
                            if element.is_displayed():
                                text1 = element.text.strip()
                                text2 = element.get_attribute('textContent').strip() if element.get_attribute('textContent') else ""
                                text3 = element.get_attribute('innerText').strip() if element.get_attribute('innerText') else ""
                                
                                text = max([text1, text2, text3], key=len)
                                
                                if text:
                                    logger.info(f"      ì¶”ì¶œ ì„±ê³µ: '{text[:100]}'")
                                    return text
                        except Exception as e:
                            logger.error(f"      ìš”ì†Œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                
            except Exception as e:
                logger.error(f"      ì„ íƒì ì˜¤ë¥˜: {str(e)}")
        
        logger.error(f"\n{element_name} ì¶”ì¶œ ì™„ì „ ì‹¤íŒ¨")
        return None
    
    def check_stock_availability(self):
        """ì¬ê³  ìƒíƒœ í™•ì¸"""
        try:
            # availability div í™•ì¸
            try:
                availability_elem = self.driver.find_element(By.ID, "availability")
                availability_text = availability_elem.text.lower()
                
                if any(phrase in availability_text for phrase in [
                    'currently unavailable',
                    'out of stock',
                    'temporarily out of stock',
                    'currently not available'
                ]):
                    logger.info(f"ì¬ê³  ì—†ìŒ: {availability_text}")
                    return False
                    
                if any(phrase in availability_text for phrase in [
                    'in stock',
                    'available',
                    'only',
                    'left in stock'
                ]):
                    logger.info(f"ì¬ê³  ìˆìŒ: {availability_text}")
                    return True
                    
            except NoSuchElementException:
                logger.debug("availability ìš”ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            
            # êµ¬ë§¤ ë²„íŠ¼ í™•ì¸
            buy_buttons = [
                "add-to-cart-button",
                "buy-now-button",
                "add-to-cart-button-ubb"
            ]
            
            for button_id in buy_buttons:
                try:
                    button = self.driver.find_element(By.ID, button_id)
                    if button and button.is_enabled():
                        logger.info("êµ¬ë§¤ ë²„íŠ¼ í™œì„±í™” - ì¬ê³  ìˆìŒ")
                        return True
                except:
                    continue
            
            # ê¸°ë³¸ê°’: ì¬ê³  ìˆìŒ
            logger.info("ì¬ê³  ìƒíƒœ ë¶ˆëª…í™• - ê¸°ë³¸ê°’: ì¬ê³  ìˆìŒ")
            return True
            
        except Exception as e:
            logger.warning(f"ì¬ê³  í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
            return True
    
    def apply_price_zero_rule(self, ships_from, sold_by, price):
        """ships_fromê³¼ sold_byê°€ ëª¨ë‘ ì—†ì„ ê²½ìš° ê°€ê²©ì„ 0ìœ¼ë¡œ ì„¤ì •í•˜ëŠ” í•¨ìˆ˜"""
        try:
            # Noneì´ê±°ë‚˜ ë¹ˆ ë¬¸ìì—´ì´ê±°ë‚˜ ê³µë°±ë§Œ ìˆëŠ” ê²½ìš°ë¥¼ ëª¨ë‘ ì²´í¬
            ships_from_empty = not ships_from or not ships_from.strip()
            sold_by_empty = not sold_by or not sold_by.strip()
            
            if ships_from_empty and sold_by_empty:
                logger.info("âš ï¸ ships_fromê³¼ sold_byê°€ ëª¨ë‘ ì—†ìŒ -> ê°€ê²©ì„ 0ìœ¼ë¡œ ì„¤ì •")
                return None
            else:
                logger.info(f"âœ… ships_from ë˜ëŠ” sold_by ì¤‘ í•˜ë‚˜ ì´ìƒ ì¡´ì¬ -> ê¸°ì¡´ ê°€ê²© ìœ ì§€")
                return price
                
        except Exception as e:
            logger.error(f"ê°€ê²© 0 ê·œì¹™ ì ìš© ì¤‘ ì˜¤ë¥˜: {e}")
            return price
    
    def extract_product_info(self, url, row_data, retry_count=0, max_retries=3):
        """ì œí’ˆ ì •ë³´ ì¶”ì¶œ"""
        try:
            logger.info(f"\n{'='*60}")
            logger.info("ì¸ë„ Amazon ì œí’ˆ ì •ë³´ ì¶”ì¶œ")
            logger.info(f"URL: {url}")
            logger.info(f"ë¸Œëœë“œ: {row_data.get('brand', 'N/A')}")
            logger.info(f"ì œí’ˆ: {row_data.get('item', 'N/A')}")
            
            # í˜ì´ì§€ ë¡œë“œ
            self.driver.get(url)
            time.sleep(random.uniform(3, 6))
            
            # ì°¨ë‹¨ í˜ì´ì§€ ì²˜ë¦¬
            page_source_lower = self.driver.page_source.lower()
            if 'continue shopping' in page_source_lower:
                logger.info("âš ï¸ ì°¨ë‹¨ í˜ì´ì§€ ê°ì§€")
                self.handle_captcha_or_block_page(url)
                time.sleep(3)
            
            # ì°¨ë‹¨ í™•ì¸
            if self.is_page_blocked():
                logger.error("âŒ í˜ì´ì§€ ì°¨ë‹¨ë¨")
                raise Exception("í˜ì´ì§€ ì°¨ë‹¨ë¨")
            
            # í˜„ì¬ ì‹œê°„
            now_time = datetime.now(self.korea_tz)
            
            # ê¸°ë³¸ ê²°ê³¼ êµ¬ì¡°
            result = {
                'retailerid': row_data.get('retailerid', ''),
                'country_code': 'in',
                'ships_from': None,
                'channel': row_data.get('channel', 'Online'),
                'retailersku': row_data.get('retailersku', ''),
                'brand': row_data.get('brand', ''),
                'brand_eng': row_data.get('brand_eng', row_data.get('brand', '')),
                'form_factor': row_data.get('form_factor', ''),
                'segment_lv1': row_data.get('seg_lv1', ''),
                'segment_lv2': row_data.get('seg_lv2', ''),
                'segment_lv3': row_data.get('seg_lv3', ''),
                'capacity': row_data.get('capacity', ''),
                'item': row_data.get('item', ''),
                'retailprice': None,
                'sold_by': None,
                'imageurl': None,
                'producturl': url,
                'crawl_datetime': now_time.strftime('%Y-%m-%d %H:%M:%S'),
                'crawl_strdatetime': now_time.strftime('%Y%m%d%H%M%S') + f"{now_time.microsecond:06d}"[:4],
                'title': None,
                'vat': row_data.get('vat', 'o')
            }
            
            # ì œëª© ì¶”ì¶œ
            result['title'] = self.extract_element_text(
                self.selectors['in']['title'], 
                "ì œëª©"
            )
            
            # ì¬ê³  í™•ì¸
            has_stock = self.check_stock_availability()
            
            # ë£¨í”¼ ê°€ê²© ì¶”ì¶œ
            result['retailprice'] = self.extract_price_india()
            
            # Ships From ì¶”ì¶œ (ì¸ë„ ì „ìš© í•¨ìˆ˜ ì‚¬ìš©)
            result['ships_from'] = self.extract_ships_from_india()
            
            # íŒë§¤ì ì •ë³´ ì¶”ì¶œ (ì¸ë„ ì „ìš© í•¨ìˆ˜ ì‚¬ìš©)
            result['sold_by'] = self.extract_sold_by_india()
            
            # ships_fromê³¼ sold_byê°€ ëª¨ë‘ ì—†ì„ ê²½ìš° ê°€ê²©ì„ 0ìœ¼ë¡œ ì„¤ì •
            result['retailprice'] = self.apply_price_zero_rule(
                result['ships_from'], 
                result['sold_by'], 
                result['retailprice']
            )
            
            # ì¬ê³  ì—†ê³  ê°€ê²© ì—†ìœ¼ë©´ None (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
            if not has_stock and result['retailprice'] is None:
                result['retailprice'] = None
                logger.info("ì¬ê³  ì—†ìŒ + ê°€ê²© ì—†ìŒ -> ê°€ê²© None")
            
            # ì´ë¯¸ì§€ URL ì¶”ì¶œ
            for selector in self.selectors['in']['imageurl']:
                try:
                    if selector.startswith('//'):
                        element = self.driver.find_element(By.XPATH, selector)
                    else:
                        element = self.driver.find_element(By.CSS_SELECTOR, selector)
                    
                    result['imageurl'] = element.get_attribute('src')
                    if result['imageurl']:
                        logger.debug("âœ… ì´ë¯¸ì§€ URL ì¶”ì¶œ ì„±ê³µ")
                        break
                except:
                    continue
            
            # GST/VAT í™•ì¸
            # page_source = self.driver.page_source.lower()
            
            # for vat_text in self.selectors['in']['vat_text_list']:
            #     if vat_text.lower() in page_source:
            #         result['vat'] = 'o'
            #         logger.info(f"GST/Tax í¬í•¨ í™•ì¸: {vat_text}")
            #         break
            
            # ê²°ê³¼ ìš”ì•½
            logger.info(f"\nğŸ“Š ì¸ë„ ì¶”ì¶œ ê²°ê³¼:")
            logger.info(f"   ğŸ“Œ ì œëª©: {result['title'][:50] + '...' if result['title'] and len(result['title']) > 50 else result['title']}")
            logger.info(f"   ğŸ’° ê°€ê²©: â‚¹{result['retailprice']}" if result['retailprice'] else "   ğŸ’° ê°€ê²©: ì—†ìŒ")
            logger.info(f"   ğŸš¢ Ships From: {result['ships_from']}")
            logger.info(f"   ğŸª íŒë§¤ì: {result['sold_by']}")
            # logger.info(f"   ğŸ’¸ GST: {result['vat']}")
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ í˜ì´ì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            
            if retry_count < max_retries:
                wait_time = (retry_count + 1) * 10
                logger.info(f"ğŸ”„ {wait_time}ì´ˆ í›„ ì¬ì‹œë„... ({retry_count + 1}/{max_retries})")
                time.sleep(wait_time)
                
                try:
                    self.driver.refresh()
                except:
                    logger.info("ğŸ”§ ë“œë¼ì´ë²„ ì¬ì‹œì‘")
                    self.driver.quit()
                    self.setup_driver()
                
                return self.extract_product_info(url, row_data, retry_count + 1, max_retries)
            
            # ìµœì¢… ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’
            now_time = datetime.now(self.korea_tz)
            return {
                'retailerid': row_data.get('retailerid', ''),
                'country_code': 'in',
                'ships_from': None,
                'channel': row_data.get('channel', 'Online'),
                'retailersku': row_data.get('retailersku', ''),
                'brand': row_data.get('brand', ''),
                'brand_eng': row_data.get('brand_eng', row_data.get('brand', '')),
                'form_factor': row_data.get('form_factor', ''),
                'segment_lv1': row_data.get('seg_lv1', ''),
                'segment_lv2': row_data.get('seg_lv2', ''),
                'segment_lv3': row_data.get('seg_lv3', ''),
                'capacity': row_data.get('capacity', ''),
                'item': row_data.get('item', ''),
                'retailprice': None,
                'sold_by': None,
                'imageurl': None,
                'producturl': url,
                'crawl_datetime': now_time.strftime('%Y-%m-%d %H:%M:%S'),
                'crawl_strdatetime': now_time.strftime('%Y%m%d%H%M%S') + f"{now_time.microsecond:06d}"[:4],
                'title': None,
                'vat': row_data.get('vat', 'o')
            }
    
    def get_crawl_targets(self, limit=None):
        """DBì—ì„œ ì¸ë„ í¬ë¡¤ë§ ëŒ€ìƒ ì¡°íšŒ"""
        try:
            query = """
            SELECT *
            FROM samsung_price_tracking_list
            WHERE country = 'in' 
              AND mall_name = 'amazon'
              AND is_active = TRUE
            """
                
            if limit:
                query += f" LIMIT {limit}"
            
            df = pd.read_sql(query, self.db_engine)
            logger.info(f"âœ… ì¸ë„ í¬ë¡¤ë§ ëŒ€ìƒ {len(df)}ê°œ ì¡°íšŒ")
            return df.to_dict('records')
            
        except Exception as e:
            logger.error(f"í¬ë¡¤ë§ ëŒ€ìƒ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def save_to_db(self, df):
        """DBì— ê²°ê³¼ ì €ì¥ - í†µí™”ê¸°í˜¸ ì œê±° ë° ì •ìˆ˜/ì†Œìˆ˜ì  ìë™ ì²˜ë¦¬"""
        if self.db_engine is None:
            logger.info("DB ì—°ê²°ì´ ì—†ì–´ DB ì €ì¥ ê±´ë„ˆëœ€")
            return False
        
        try:
            # ê°€ê²© ì»¬ëŸ¼ì—ì„œ í†µí™”ê¸°í˜¸ ì œê±° ë° ì •ìˆ˜/ì†Œìˆ˜ì  ì²˜ë¦¬
            if 'retailprice' in df.columns:
                # ë¬¸ìì—´ë¡œ ì €ì¥ëœ ê°€ê²©ì´ ìˆë‹¤ë©´ ìˆ«ìë¡œ ë³€í™˜
                df['retailprice'] = pd.to_numeric(df['retailprice'], errors='coerce')
                
                # ì†Œìˆ˜ì  ì´í•˜ê°€ 0ì¸ ê²½ìš° ì •ìˆ˜ë¡œ ë³€í™˜
                mask = df['retailprice'].notna()
                df.loc[mask, 'retailprice'] = df.loc[mask, 'retailprice'].apply(
                    lambda x: int(x) if x == int(x) else x
                )
                
                logger.info("âœ… ê°€ê²© ë°ì´í„° ì •ìˆ˜/ì†Œìˆ˜ì  ìë™ ì²˜ë¦¬ ì™„ë£Œ")
            
            table_name = 'amazon_price_crawl_tbl_ind'
            df.to_sql(table_name, self.db_engine, if_exists='append', index=False)
            logger.info(f"âœ… ì¸ë„ DB ì €ì¥: {len(df)}ê°œ â†’ {table_name}")
            
            # ì €ì¥ëœ ê°€ê²© ë°ì´í„° ìƒ˜í”Œ ë¡œê·¸ (ì²œë‹¨ìœ„ êµ¬ë¶„ì í¬í•¨)
            price_data = df[df['retailprice'].notna()]['retailprice'].head(3)
            if not price_data.empty:
                formatted_prices = []
                for price in price_data:
                    if price == int(price):
                        formatted_prices.append(f"{int(price):,}")
                    else:
                        formatted_prices.append(f"{price:,.2f}")
                logger.info(f"ğŸ’° ì €ì¥ëœ ê°€ê²© ìƒ˜í”Œ: {formatted_prices}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ DB ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    def upload_to_file_server(self, local_file_path, remote_filename=None):
        """íŒŒì¼ì„œë²„ì— ì—…ë¡œë“œ"""
        try:
            transport = paramiko.Transport((FILE_SERVER_CONFIG['host'], FILE_SERVER_CONFIG['port']))
            transport.connect(
                username=FILE_SERVER_CONFIG['username'],
                password=FILE_SERVER_CONFIG['password']
            )
            sftp = paramiko.SFTPClient.from_transport(transport)
            
            if remote_filename is None:
                remote_filename = os.path.basename(local_file_path)
            
            country_dir = f"{FILE_SERVER_CONFIG['upload_path']}/in"
            
            try:
                sftp.stat(country_dir)
            except FileNotFoundError:
                logger.info(f"ğŸ“ ì¸ë„ ë””ë ‰í† ë¦¬ ìƒì„±: {country_dir}")
                sftp.mkdir(country_dir)
            
            remote_path = f"{country_dir}/{remote_filename}"
            sftp.put(local_file_path, remote_path)
            logger.info(f"âœ… ì¸ë„ íŒŒì¼ì„œë²„ ì—…ë¡œë“œ: {remote_path}")
            
            sftp.close()
            transport.close()
            return True
            
        except Exception as e:
            logger.error(f"âŒ íŒŒì¼ì„œë²„ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def save_results(self, df, save_db=True, upload_server=True):
        """ê²°ê³¼ ì €ì¥"""
        now = datetime.now(self.korea_tz)
        date_str = now.strftime("%Y%m%d")
        time_str = now.strftime("%H%M%S")
        
        base_filename = f"{date_str}{time_str}_in_amazon"
        
        results = {
            'db_saved': False,
            'server_uploaded': False
        }
        
        if save_db:
            results['db_saved'] = self.save_to_db(df)
        
        if upload_server:
            try:
                # CSV íŒŒì¼
                temp_csv = f'temp_{base_filename}.csv'
                df.to_csv(temp_csv, index=False, encoding='utf-8-sig')
                
                if self.upload_to_file_server(temp_csv, f'{base_filename}.csv'):
                    results['server_uploaded'] = True
                
                # Excel íŒŒì¼
                temp_excel = f'temp_{base_filename}.xlsx'
                with pd.ExcelWriter(temp_excel, engine='openpyxl') as writer:
                    df.to_excel(writer, sheet_name='India_Results', index=False)
                    
                    price_df = df[df['retailprice'].notna()]
                    if not price_df.empty:
                        price_df.to_excel(writer, sheet_name='With_Prices', index=False)
                    
                    summary = pd.DataFrame({
                        'Metric': [
                            'Total Products', 
                            'Products with Price', 
                            'Products without Price', 
                            'Success Rate (%)',
                            'Crawl Date',
                            'Country',
                            'Mall Name'
                        ],
                        'Value': [
                            len(df),
                            df['retailprice'].notna().sum(),
                            df['retailprice'].isna().sum(),
                            round(df['retailprice'].notna().sum() / len(df) * 100, 2) if len(df) > 0 else 0,
                            now.strftime('%Y-%m-%d %H:%M:%S'),
                            'India',
                            'Amazon'
                        ]
                    })
                    summary.to_excel(writer, sheet_name='Summary', index=False)
                
                # self.upload_to_file_server(temp_excel, f'{base_filename}.xlsx')
                
                # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                for temp_file in [temp_csv, temp_excel]:
                    if os.path.exists(temp_file):
                        os.remove(temp_file)
                
            except Exception as e:
                logger.error(f"íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        
        return results
    
    def scrape_urls(self, urls_data, max_items=None):
        """URL ìŠ¤í¬ë˜í•‘"""
        if max_items:
            urls_data = urls_data[:max_items]
        
        logger.info(f"\n{'='*80}")
        logger.info("ğŸ‡®ğŸ‡³ Amazon India í¬ë¡¤ë§ ì‹œì‘")
        logger.info(f"ğŸ“Œ ëŒ€ìƒ: {len(urls_data)}ê°œ ì œí’ˆ")
        logger.info(f"{'='*80}\n")
        
        if not self.setup_driver():
            logger.error("ë“œë¼ì´ë²„ ì„¤ì • ì‹¤íŒ¨")
            return None
        
        results = []
        
        try:
            for idx, row in enumerate(urls_data):
                logger.info(f"\nì§„í–‰ë¥ : {idx + 1}/{len(urls_data)} ({(idx + 1)/len(urls_data)*100:.1f}%)")
                
                url = row.get('url')
                result = self.extract_product_info(url, row)
                results.append(result)
                
                # ëŒ€ê¸°
                if idx < len(urls_data) - 1:
                    wait_time = random.uniform(5, 10)
                    logger.info(f"â³ {wait_time:.1f}ì´ˆ ëŒ€ê¸°...")
                    time.sleep(wait_time)
        
        except Exception as e:
            logger.error(f"âŒ ìŠ¤í¬ë˜í•‘ ì˜¤ë¥˜: {e}")
        
        finally:
            if self.driver:
                self.driver.quit()
        
        return pd.DataFrame(results)
    
    def analyze_results(self, df):
        """ê²°ê³¼ ë¶„ì„"""
        logger.info("\nAmazon India ê²°ê³¼ ë¶„ì„")
        logger.info("="*40)
        
        total = len(df)
        with_price = df['retailprice'].notna().sum()
        success_rate = (with_price / total * 100) if total > 0 else 0
        
        logger.info(f"ì „ì²´ ì œí’ˆ: {total}ê°œ")
        logger.info(f"ê°€ê²© ì¶”ì¶œ ì„±ê³µ: {with_price}ê°œ")
        logger.info(f"ì„±ê³µë¥ : {success_rate:.1f}%")
        
        if with_price > 0:
            price_df = df[df['retailprice'].notna()]
            logger.info("\nê°€ê²© í†µê³„:")
            
            # í†µê³„ê°’ë„ ì •ìˆ˜/ì†Œìˆ˜ì  ìë™ ì²˜ë¦¬
            mean_price = price_df['retailprice'].mean()
            min_price = price_df['retailprice'].min()
            max_price = price_df['retailprice'].max()
            median_price = price_df['retailprice'].median()
            
            # ì†Œìˆ˜ì  ì´í•˜ê°€ 0ì´ë©´ ì •ìˆ˜ë¡œ í‘œì‹œ (ì²œë‹¨ìœ„ êµ¬ë¶„ì í¬í•¨)
            def format_price(price):
                if price == int(price):
                    return f"{int(price):,}"  # ì²œë‹¨ìœ„ êµ¬ë¶„ì í¬í•¨
                else:
                    return f"{price:,.2f}"    # ì†Œìˆ˜ì ë„ ì²œë‹¨ìœ„ êµ¬ë¶„ì í¬í•¨
            
            logger.info(f"   í‰ê· ê°€: {format_price(mean_price)}")
            logger.info(f"   ìµœì €ê°€: {format_price(min_price)}")
            logger.info(f"   ìµœê³ ê°€: {format_price(max_price)}")
            logger.info(f"   ì¤‘ê°„ê°’: {format_price(median_price)}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    test_mode = os.getenv('TEST_MODE', 'false').lower() == 'true'
    max_items = int(os.getenv('MAX_ITEMS', '0')) or None
    
    print(f"\n{'='*80}")
    print("ğŸ‡®ğŸ‡³ Amazon India ê°€ê²© ì¶”ì¶œ ì‹œìŠ¤í…œ v1.0")
    print(f"{'='*80}")
    print("ğŸ“Œ êµ­ê°€: India")
    print(f"ğŸ“Œ ëª¨ë“œ: {'í…ŒìŠ¤íŠ¸' if test_mode else 'ì‹¤ì œ'}")
    if max_items:
        print(f"ğŸ“Œ ìµœëŒ€ ì²˜ë¦¬ ìˆ˜: {max_items}ê°œ")
    print(f"{'='*80}\n")
    
    # ìŠ¤í¬ë˜í¼ ì´ˆê¸°í™”
    scraper = AmazonIndiaScraper()
    
    if scraper.db_engine is None:
        logger.error("DB ì—°ê²° ì‹¤íŒ¨ë¡œ ì¢…ë£Œ")
        return
    
    # í…ŒìŠ¤íŠ¸ ëª¨ë“œ
    if test_mode:
        logger.info("ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ ì‹¤í–‰...")
        test_data = [{
            'url': 'https://www.amazon.in/dp/B0CTRXBKHP',
            'brand': 'Crucial',
            'item': 'T705 1TB',
            'retailerid': 'TEST001',
            'retailersku': 'TEST001',
            'channel': 'Online',
            'seg_lv1': 'SSD',
            'seg_lv2': 'Consumer',
            'seg_lv3': 'NVMe',
            'capacity': '1TB',
            'form_factor': 'M.2'
        }]
        
        results_df = scraper.scrape_urls(test_data)
        if results_df is not None and not results_df.empty:
            scraper.analyze_results(results_df)
            scraper.save_results(results_df, save_db=False, upload_server=True)
        return
    
    # ì‹¤ì œ í¬ë¡¤ë§
    logger.info("ğŸ“Š ì¸ë„ ì „ì²´ í¬ë¡¤ë§ ì‹œì‘")
    urls_data = scraper.get_crawl_targets(limit=max_items)
    
    if not urls_data:
        logger.warning("í¬ë¡¤ë§ ëŒ€ìƒì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    logger.info(f"âœ… í¬ë¡¤ë§ ëŒ€ìƒ: {len(urls_data)}ê°œ")
    
    results_df = scraper.scrape_urls(urls_data, max_items)
    
    if results_df is None or results_df.empty:
        logger.error("í¬ë¡¤ë§ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    scraper.analyze_results(results_df)
    
    save_results = scraper.save_results(
        results_df,
        save_db=True,
        upload_server=True
    )
    
    logger.info(f"\n{'='*80}")
    logger.info("ğŸ‡®ğŸ‡³ ì¸ë„ ì €ì¥ ê²°ê³¼")
    logger.info(f"{'='*80}")
    logger.info(f"DB ì €ì¥: {'âœ… ì„±ê³µ' if save_results['db_saved'] else 'âŒ ì‹¤íŒ¨'}")
    logger.info(f"íŒŒì¼ì„œë²„ ì—…ë¡œë“œ: {'âœ… ì„±ê³µ' if save_results['server_uploaded'] else 'âŒ ì‹¤íŒ¨'}")
    
    logger.info(f"\n{'='*80}")
    logger.info("âœ… ì¸ë„ í¬ë¡¤ë§ ì™„ë£Œ!")
    logger.info(f"{'='*80}\n")

if __name__ == "__main__":
    print("\nğŸ“¦ í•„ìš”í•œ íŒ¨í‚¤ì§€:")
    print("pip install undetected-chromedriver selenium pandas pymysql sqlalchemy paramiko openpyxl")
    print("\nâš ï¸ í™˜ê²½ë³€ìˆ˜ ì„¤ì •:")
    print("export TEST_MODE=false")
    print("export MAX_ITEMS=10")
    print()
    
    main()